![](https://github.com/Rodea41/Machine-Learning-Algorithms/blob/main/img.jpg)

<img src="[http://....jpg](https://github.com/Rodea41/Machine-Learning-Algorithms/blob/main/img.jpg)" width="200" height="200" />


# Machine-Learning-Algorithms

## Table of Contents
- [Introduction](#introduction)
- [Algorithms](#algorithms)
- [Installation](#installation)
- [Usage](#usage)
- [Notebook Details](#notebook-details)
- [Contributing](#contributing)
- [License](#license)

## Introduction
This repository contains various machine learning algorithms implemented during my time at Fresno State. The goal is to provide a comprehensive collection of examples and insights into machine learning techniques.

## Algorithms
The following algorithms are included:
- Linear Regression
- Logistic Regression
- Decision Trees
- Random Forests
- Support Vector Machines (SVM)
- K-Nearest Neighbors (KNN)
- K-Means Clustering
- Neural Networks

## Notebook Details
Each notebook in this repository demonstrates the implementation of a specific machine learning algorithm. Below are the details:

1. **Linear Regression**:
   - File: `linear_regression.ipynb`
   - Description: Demonstrates simple and multiple linear regression using a sample dataset. Includes data visualization and performance evaluation.
   - Use Case: Linear regression is used for predicting numerical outcomes, such as house prices, stock prices, or sales figures, based on input features.

2. **Logistic Regression**:
   - File: `logistic_regression.ipynb`
   - Description: Implements binary classification using logistic regression. Includes ROC curve analysis and accuracy metrics.
   - Use Case: Logistic regression is used for classification problems, such as determining whether an email is spam, predicting customer churn, or diagnosing diseases (e.g., diabetes: yes/no).
   - 
3. **Decision Trees**:
   - File: `decision_trees.ipynb`
   - Description: Explores decision tree classifiers with examples of tree visualization and pruning techniques.
   - Use Case: Decision trees are used for both classification and regression tasks. They are intuitive and can handle non-linear relationships. Examples include loan approval prediction and customer segmentation.

4. **Random Forests**:
   - File: `random_forests.ipynb`
   - Description: Implements ensemble learning using random forests for classification and regression tasks.
   - Use Case: Random forests are used for robust predictions in tasks like fraud detection, stock market forecasting, and medical diagnosis.

5. **Support Vector Machines (SVM)**:
   - File: `svm.ipynb`
   - Description: Demonstrates SVM for both linear and non-linear classification problems. Includes kernel trick examples.
   - Use Case: SVM is used for classification tasks like image recognition, text categorization, and bioinformatics (e.g., cancer classification).

6. **K-Nearest Neighbors (KNN)**:
   - File: `knn.ipynb`
   - Description: Implements KNN for classification tasks with hyperparameter tuning for optimal performance.
   - Use Case: KNN is used for classification problems like handwriting recognition, recommendation systems, and anomaly detection.

7. **K-Means Clustering**:
   - File: `k_means_clustering.ipynb`
   - Description: Demonstrates unsupervised learning using K-Means clustering. Includes elbow method for determining the optimal number of clusters.
   - Use Case: K-Means is used for grouping similar data points, such as customer segmentation, market research, and image compression.

8. **Neural Networks**:
   - File: `neural_networks.ipynb`
   - Description: Implements a basic neural network using TensorFlow/Keras. Includes examples of training, validation, and testing.
   - Use Case: Neural networks are used for complex tasks like image recognition, natural language processing, and time-series forecasting. Examples include facial recognition, sentiment analysis, and stock price prediction.
